{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATAPATH = \"path to train data\"\n",
    "TEST_DATAPATH = \"path to test data\"\n",
    "TRAIN_OUTPUT_PATH = \"output path for train data\"\n",
    "TEST_OUTPUT_PATH = \"output path for test data\"\n",
    "\n",
    "if not os.path.exists(TRAIN_OUTPUT_PATH):\n",
    "    os.makedirs(TRAIN_OUTPUT_PATH)\n",
    "if not os.path.exists(TEST_OUTPUT_PATH):\n",
    "    os.makedirs(TEST_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file_list(reader_list, path):\n",
    "    cur_path = os.walk(path)\n",
    "    for root, directories, files in cur_path:\n",
    "        for file in files:\n",
    "            reader_list.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "\n",
    "make_file_list(train_list, TRAIN_DATAPATH)\n",
    "train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "\n",
    "make_file_list(test_list, TEST_DATAPATH)\n",
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meaning of each feature\n",
    "# https://github.com/CanadianInstituteForCybersecurity/\n",
    "# CICFlowMeter/blob/master/ReadMe.txt\n",
    "\n",
    "# this list includes all spellings across CIC NIDS datasets\n",
    "drop_cols = [\n",
    "    \"Flow ID\",    \n",
    "    \" Fwd Header Length.1\",\n",
    "    \" Source IP\",\n",
    "    \" Source Port\",\n",
    "    \" Destination IP\",\n",
    "    \" Destination Port\",\n",
    "    \" Timestamp\",\n",
    "    # CIC-DDoS other undocumented columns\n",
    "    \"Unnamed: 0\", \" Inbound\", \"SimillarHTTP\" \n",
    "]\n",
    "\n",
    "def process_data(reader: pd.DataFrame, output_fn: str):\n",
    "\n",
    "    # drop the columns not intended for use\n",
    "    reader.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    # remove NaN\n",
    "    reader.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    reader.dropna(inplace=True)\n",
    "\n",
    "    # drop duplicates\n",
    "    reader.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # rename the label for binary classification task\n",
    "    reader[\" Label\"].replace({'BENIGN': int(0)}, inplace=True)\n",
    "    reader[\" Label\"] = reader[\" Label\"].apply(lambda x: int(1) if x != int(0) else x)\n",
    "\n",
    "    # dump preprocessed data\n",
    "    reader.to_csv(\n",
    "        output_fn, header=(not os.path.exists(output_fn)), \n",
    "        index=False, mode='a'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKSIZE = 50000\n",
    "\n",
    "def read_file(filelist: list, output_path: str) -> None:\n",
    "    for file in filelist:\n",
    "\n",
    "        # Skip the .~lock.UDPLag.csv# file in test set\n",
    "        if file.split(sep='.')[1] == \"csv\":\n",
    "            print(f\"File reading now: {file}\")\n",
    "            filename = file.split(sep=\"\\\\\")[1]\n",
    "            output_fn = output_path + '/' + filename.split(sep='.')[0] + \"_preprocessed.csv\"\n",
    "            \n",
    "            with pd.read_csv(file, chunksize=CHUNKSIZE, low_memory=False) as reader:\n",
    "                for chunk in reader:\n",
    "                    chunk[\" Protocol\"].astype(\"int32\")\n",
    "                    process_data(chunk, output_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file(train_list, TRAIN_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file(test_list, TEST_OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
